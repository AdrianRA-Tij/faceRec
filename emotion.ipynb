{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import model_from_json\n",
    "from keras.layers.pooling import AveragePooling2D\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "1610\n",
      "['/home/servidorubuntu/Escritorio/Emociones/dataset/SAD/03_059.jpg', '/home/servidorubuntu/Escritorio/Emociones/dataset/FEARFUL/04_094.jpg', '/home/servidorubuntu/Escritorio/Emociones/dataset/NEUTRAL/01_189.jpg', '/home/servidorubuntu/Escritorio/Emociones/dataset/HAPPY/02_140.jpg', '/home/servidorubuntu/Escritorio/Emociones/dataset/NEUTRAL/01_001.jpg', '/home/servidorubuntu/Escritorio/Emociones/dataset/FEARFUL/04_069.jpg', '/home/servidorubuntu/Escritorio/Emociones/dataset/DISGUSTED/07_193.jpg', '/home/servidorubuntu/Escritorio/Emociones/dataset/ANGRY/05_173.jpg', '/home/servidorubuntu/Escritorio/Emociones/dataset/NEUTRAL/01_048.jpg', '/home/servidorubuntu/Escritorio/Emociones/dataset/FEARFUL/04_095.jpg']\n"
     ]
    }
   ],
   "source": [
    "IMAGE_DIMS = (64, 64, 3)\n",
    "# initialize the data and labels\n",
    "data = []\n",
    "labels = []\n",
    "face_cascade = cv2.CascadeClassifier('/home/servidorubuntu/opencv-master/data/haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Convolutional Neural Network\n",
    "# grab the image paths and randomly shuffle them\n",
    "print(\"[INFO] loading images...\")\n",
    "path = '/home/servidorubuntu/Escritorio/Emociones/dataset'\n",
    "imagePaths = sorted(list(paths.list_images(path)))\n",
    "print(len(imagePaths))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "print(imagePaths[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    face = face_cascade.detectMultiScale(image, 1.1, 7)\n",
    "    x = face[0][0]\n",
    "    y = face[0][1]\n",
    "    w = face[0][2]\n",
    "    h = face[0][3]\n",
    "    #print(x,y,h,w)\n",
    "    crop_img = image[y:y+h, x:x+w]\n",
    "    img = cv2.resize(crop_img, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "    #img = img_to_array(img)    \n",
    "    data.append(img)\n",
    " \n",
    "    # extract the class label from the image path and update the\n",
    "    # labels list\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)\n",
    "\n",
    "data = np.array(data, dtype=\"float\") / 255\n",
    "# binarize the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.60392157 0.62745098 0.64705882]\n",
      "   [0.40392157 0.45098039 0.49019608]\n",
      "   [0.23921569 0.28627451 0.33333333]\n",
      "   ...\n",
      "   [0.28627451 0.36078431 0.38431373]\n",
      "   [0.54509804 0.57647059 0.57647059]\n",
      "   [0.61568627 0.63529412 0.63137255]]\n",
      "\n",
      "  [[0.45098039 0.48627451 0.50196078]\n",
      "   [0.23921569 0.28235294 0.3372549 ]\n",
      "   [0.2627451  0.33333333 0.38431373]\n",
      "   ...\n",
      "   [0.29019608 0.38039216 0.44313725]\n",
      "   [0.32156863 0.41176471 0.43921569]\n",
      "   [0.59607843 0.62352941 0.61176471]]\n",
      "\n",
      "  [[0.40784314 0.44313725 0.47843137]\n",
      "   [0.28627451 0.34117647 0.41176471]\n",
      "   [0.25490196 0.32156863 0.38823529]\n",
      "   ...\n",
      "   [0.27058824 0.34509804 0.41176471]\n",
      "   [0.30196078 0.37254902 0.44313725]\n",
      "   [0.34901961 0.41960784 0.45098039]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.74901961 0.74509804 0.75294118]\n",
      "   [0.74117647 0.7372549  0.74509804]\n",
      "   [0.73333333 0.74117647 0.74509804]\n",
      "   ...\n",
      "   [0.69411765 0.69411765 0.69411765]\n",
      "   [0.69019608 0.69803922 0.69803922]\n",
      "   [0.67843137 0.68627451 0.68627451]]\n",
      "\n",
      "  [[0.73333333 0.72941176 0.7372549 ]\n",
      "   [0.74117647 0.7372549  0.74509804]\n",
      "   [0.73333333 0.74117647 0.74509804]\n",
      "   ...\n",
      "   [0.69411765 0.69411765 0.69411765]\n",
      "   [0.69019608 0.69803922 0.69803922]\n",
      "   [0.69019608 0.69803922 0.69803922]]\n",
      "\n",
      "  [[0.73333333 0.74117647 0.74509804]\n",
      "   [0.7372549  0.74509804 0.74901961]\n",
      "   [0.73333333 0.74117647 0.74509804]\n",
      "   ...\n",
      "   [0.68627451 0.69411765 0.69411765]\n",
      "   [0.69411765 0.69411765 0.69411765]\n",
      "   [0.69411765 0.69411765 0.69411765]]]\n",
      "\n",
      "\n",
      " [[[0.76862745 0.74509804 0.74901961]\n",
      "   [0.28235294 0.26666667 0.29019608]\n",
      "   [0.20392157 0.18823529 0.20784314]\n",
      "   ...\n",
      "   [0.83137255 0.85098039 0.84705882]\n",
      "   [0.83921569 0.85882353 0.85490196]\n",
      "   [0.84705882 0.85490196 0.85490196]]\n",
      "\n",
      "  [[0.34117647 0.31764706 0.32156863]\n",
      "   [0.21568627 0.20392157 0.21176471]\n",
      "   [0.19607843 0.18823529 0.19215686]\n",
      "   ...\n",
      "   [0.83921569 0.85882353 0.85490196]\n",
      "   [0.83137255 0.85098039 0.84705882]\n",
      "   [0.84705882 0.85490196 0.85490196]]\n",
      "\n",
      "  [[0.25882353 0.23921569 0.24313725]\n",
      "   [0.16078431 0.15294118 0.15294118]\n",
      "   [0.20784314 0.2        0.2       ]\n",
      "   ...\n",
      "   [0.83921569 0.85882353 0.85490196]\n",
      "   [0.82745098 0.84705882 0.84313725]\n",
      "   [0.84705882 0.85490196 0.85490196]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.42352941 0.43529412 0.45490196]\n",
      "   [0.57647059 0.58823529 0.60784314]\n",
      "   [0.17254902 0.18823529 0.19215686]\n",
      "   ...\n",
      "   [0.2627451  0.25882353 0.25882353]\n",
      "   [0.45882353 0.44705882 0.46666667]\n",
      "   [0.14117647 0.16862745 0.18431373]]\n",
      "\n",
      "  [[0.39215686 0.39215686 0.40784314]\n",
      "   [0.07843137 0.07843137 0.08627451]\n",
      "   [0.08627451 0.09019608 0.09019608]\n",
      "   ...\n",
      "   [0.19607843 0.22352941 0.22352941]\n",
      "   [0.15686275 0.19215686 0.19607843]\n",
      "   [0.34117647 0.37254902 0.38431373]]\n",
      "\n",
      "  [[0.12156863 0.11764706 0.1254902 ]\n",
      "   [0.0745098  0.0745098  0.0745098 ]\n",
      "   [0.04313725 0.04313725 0.04313725]\n",
      "   ...\n",
      "   [0.10980392 0.11764706 0.12156863]\n",
      "   [0.11372549 0.12941176 0.13333333]\n",
      "   [0.16862745 0.19215686 0.20392157]]]\n",
      "\n",
      "\n",
      " [[[0.69411765 0.69411765 0.69411765]\n",
      "   [0.69803922 0.69803922 0.69803922]\n",
      "   [0.68627451 0.68627451 0.68627451]\n",
      "   ...\n",
      "   [0.57647059 0.58431373 0.58431373]\n",
      "   [0.57647059 0.58431373 0.58431373]\n",
      "   [0.56078431 0.58039216 0.57254902]]\n",
      "\n",
      "  [[0.69019608 0.69019608 0.69019608]\n",
      "   [0.69411765 0.69411765 0.69411765]\n",
      "   [0.69411765 0.69411765 0.69411765]\n",
      "   ...\n",
      "   [0.56862745 0.58823529 0.58431373]\n",
      "   [0.56862745 0.58823529 0.58431373]\n",
      "   [0.56862745 0.58823529 0.58431373]]\n",
      "\n",
      "  [[0.69803922 0.69803922 0.69803922]\n",
      "   [0.69803922 0.69803922 0.69803922]\n",
      "   [0.68627451 0.68627451 0.68627451]\n",
      "   ...\n",
      "   [0.56862745 0.58823529 0.58431373]\n",
      "   [0.56862745 0.58823529 0.58431373]\n",
      "   [0.57254902 0.59215686 0.58823529]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.74117647 0.74117647 0.74117647]\n",
      "   [0.7372549  0.7372549  0.7372549 ]\n",
      "   [0.73333333 0.73333333 0.73333333]\n",
      "   ...\n",
      "   [0.64705882 0.65490196 0.65490196]\n",
      "   [0.63921569 0.64705882 0.64705882]\n",
      "   [0.64705882 0.65490196 0.65490196]]\n",
      "\n",
      "  [[0.72941176 0.72941176 0.72941176]\n",
      "   [0.7372549  0.7372549  0.7372549 ]\n",
      "   [0.73333333 0.73333333 0.73333333]\n",
      "   ...\n",
      "   [0.65882353 0.65882353 0.65882353]\n",
      "   [0.65882353 0.65882353 0.65882353]\n",
      "   [0.65490196 0.65490196 0.65490196]]\n",
      "\n",
      "  [[0.72941176 0.72941176 0.72941176]\n",
      "   [0.73333333 0.73333333 0.73333333]\n",
      "   [0.73333333 0.73333333 0.73333333]\n",
      "   ...\n",
      "   [0.65882353 0.65882353 0.65882353]\n",
      "   [0.65882353 0.65882353 0.65882353]\n",
      "   [0.65490196 0.65490196 0.65490196]]]]\n",
      "(1610, 64, 64, 3)\n",
      "labels [[0 0 0 ... 0 1 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(data[:3])\n",
    "print(data.shape)\n",
    "print(\"labels {}\".format(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0 0]]\n",
      "(1610, 7)\n",
      "Labels [[0 0 0 ... 0 1 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(labels[0:10])\n",
    "print(labels.shape)\n",
    "print(\"Labels {}\".format(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 80% of\n",
    "# the data for training and the remaining 20% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,labels,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size 1610\n",
      "(1610, 7)\n",
      "(1288, 64, 64, 3) (322, 64, 64, 3)\n",
      "(1288, 7) (322, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size {}\".format(len(labels)))\n",
    "print(labels.shape)\n",
    "print(trainX.shape, testX.shape)\n",
    "print(trainY.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "\n",
    "def build(width, height, depth, classes):\n",
    "\t# initialize the model along with the input shape to be\n",
    "\t# \"channels last\" and the channels dimension itself\n",
    "\tmodel = Sequential()\n",
    "\tinputShape = (height, width, depth)\n",
    "\tchanDim = -1\n",
    " \n",
    "\t# if we are using \"channels first\", update the input shape\n",
    "\t# and channels dimension\n",
    "\tif K.image_data_format() == \"channels_first\":\n",
    "\t\tinputShape = (depth, height, width)\n",
    "\t\tchanDim = 1\n",
    "\t# CONV => RELU => POOL\n",
    "\tmodel.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "\t\tinput_shape=inputShape))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\t# (CONV => RELU) * 2 => POOL\n",
    "\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\t# (CONV => RELU) * 2 => POOL\n",
    "\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\t# first (and only) set of FC => RELU layers\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(1024))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Dropout(0.5))\n",
    " \n",
    "\t# softmax classifier\n",
    "\tmodel.add(Dense(classes))\n",
    "\tmodel.add(Activation(\"softmax\"))\n",
    " \n",
    "\t# return the constructed network architecture\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "model = build(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],\n",
    "\tdepth=IMAGE_DIMS[2], classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 21, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 21, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 21, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 21, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 10, 10, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 10, 10, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 10, 10, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              3277824   \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 7175      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 3,568,519\n",
      "Trainable params: 3,565,639\n",
      "Non-trainable params: 2,880\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# summarize layers\n",
    "print(model.summary())\n",
    "# plot graph\n",
    "plot_model(model, to_file='VGG16Example.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/30\n",
      "40/40 [==============================] - 11s 283ms/step - loss: 2.9499 - acc: 0.2352 - val_loss: 2.6714 - val_acc: 0.3354\n",
      "Epoch 2/30\n",
      "40/40 [==============================] - 10s 249ms/step - loss: 2.2155 - acc: 0.3313 - val_loss: 2.5309 - val_acc: 0.2857\n",
      "Epoch 3/30\n",
      "40/40 [==============================] - 10s 249ms/step - loss: 1.8236 - acc: 0.3977 - val_loss: 1.5301 - val_acc: 0.4720\n",
      "Epoch 4/30\n",
      "40/40 [==============================] - 10s 252ms/step - loss: 1.6644 - acc: 0.4586 - val_loss: 1.3873 - val_acc: 0.5404\n",
      "Epoch 5/30\n",
      "40/40 [==============================] - 10s 252ms/step - loss: 1.5465 - acc: 0.4438 - val_loss: 1.2701 - val_acc: 0.6087\n",
      "Epoch 6/30\n",
      "40/40 [==============================] - 11s 263ms/step - loss: 1.4478 - acc: 0.4876 - val_loss: 1.1778 - val_acc: 0.5932\n",
      "Epoch 7/30\n",
      "40/40 [==============================] - 10s 258ms/step - loss: 1.2544 - acc: 0.5336 - val_loss: 1.2880 - val_acc: 0.5404\n",
      "Epoch 8/30\n",
      "40/40 [==============================] - 10s 253ms/step - loss: 1.2988 - acc: 0.5266 - val_loss: 1.1056 - val_acc: 0.6491\n",
      "Epoch 9/30\n",
      "40/40 [==============================] - 11s 281ms/step - loss: 1.1258 - acc: 0.5640 - val_loss: 1.2950 - val_acc: 0.5621\n",
      "Epoch 10/30\n",
      "40/40 [==============================] - 10s 259ms/step - loss: 1.1213 - acc: 0.5726 - val_loss: 2.1223 - val_acc: 0.4565\n",
      "Epoch 11/30\n",
      "40/40 [==============================] - 10s 255ms/step - loss: 1.0243 - acc: 0.6234 - val_loss: 0.8345 - val_acc: 0.6988\n",
      "Epoch 12/30\n",
      "40/40 [==============================] - 11s 267ms/step - loss: 1.0257 - acc: 0.6172 - val_loss: 1.7989 - val_acc: 0.4689\n",
      "Epoch 13/30\n",
      "40/40 [==============================] - 11s 272ms/step - loss: 1.0116 - acc: 0.6164 - val_loss: 1.2195 - val_acc: 0.5963\n",
      "Epoch 14/30\n",
      "40/40 [==============================] - 11s 265ms/step - loss: 0.9373 - acc: 0.6493 - val_loss: 0.9512 - val_acc: 0.6708\n",
      "Epoch 15/30\n",
      "40/40 [==============================] - 10s 249ms/step - loss: 0.9761 - acc: 0.6594 - val_loss: 1.0478 - val_acc: 0.6273\n",
      "Epoch 16/30\n",
      "40/40 [==============================] - 10s 250ms/step - loss: 0.9701 - acc: 0.6290 - val_loss: 1.9119 - val_acc: 0.4876\n",
      "Epoch 17/30\n",
      "40/40 [==============================] - 10s 250ms/step - loss: 0.8620 - acc: 0.6508 - val_loss: 0.7299 - val_acc: 0.7143\n",
      "Epoch 18/30\n",
      "40/40 [==============================] - 10s 247ms/step - loss: 0.9421 - acc: 0.6337 - val_loss: 0.8486 - val_acc: 0.6925\n",
      "Epoch 19/30\n",
      "40/40 [==============================] - 10s 250ms/step - loss: 0.8633 - acc: 0.6627 - val_loss: 1.7631 - val_acc: 0.5124\n",
      "Epoch 20/30\n",
      "40/40 [==============================] - 10s 257ms/step - loss: 0.8592 - acc: 0.6773 - val_loss: 3.2424 - val_acc: 0.4503\n",
      "Epoch 21/30\n",
      "40/40 [==============================] - 10s 249ms/step - loss: 0.7749 - acc: 0.6999 - val_loss: 1.4118 - val_acc: 0.6087\n",
      "Epoch 22/30\n",
      "40/40 [==============================] - 10s 250ms/step - loss: 0.7895 - acc: 0.7023 - val_loss: 1.1531 - val_acc: 0.6118\n",
      "Epoch 23/30\n",
      "40/40 [==============================] - 10s 249ms/step - loss: 0.7960 - acc: 0.7023 - val_loss: 0.8464 - val_acc: 0.6988\n",
      "Epoch 24/30\n",
      "40/40 [==============================] - 10s 250ms/step - loss: 0.7524 - acc: 0.7079 - val_loss: 0.9514 - val_acc: 0.6398\n",
      "Epoch 25/30\n",
      "40/40 [==============================] - 10s 251ms/step - loss: 0.7563 - acc: 0.7094 - val_loss: 2.1714 - val_acc: 0.4752\n",
      "Epoch 26/30\n",
      "40/40 [==============================] - 10s 249ms/step - loss: 0.7289 - acc: 0.7259 - val_loss: 0.9039 - val_acc: 0.7298\n",
      "Epoch 27/30\n",
      "40/40 [==============================] - 10s 257ms/step - loss: 0.6998 - acc: 0.7408 - val_loss: 0.9264 - val_acc: 0.7143\n",
      "Epoch 28/30\n",
      "40/40 [==============================] - 11s 266ms/step - loss: 0.7107 - acc: 0.7250 - val_loss: 0.7493 - val_acc: 0.7516\n",
      "Epoch 29/30\n",
      "40/40 [==============================] - 10s 258ms/step - loss: 0.6820 - acc: 0.7345 - val_loss: 0.9844 - val_acc: 0.6770\n",
      "Epoch 30/30\n",
      "40/40 [==============================] - 10s 257ms/step - loss: 0.6972 - acc: 0.7485 - val_loss: 2.8561 - val_acc: 0.4224\n"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator(\n",
    "\taug.flow(trainX, trainY, batch_size=BS),\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tsteps_per_epoch=len(trainX) // BS,\n",
    "\tepochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig(\"EmoTrain_1.png\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 40.53%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(trainX, trainY, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"EmoClassModel.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"EmoClassWeights.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
