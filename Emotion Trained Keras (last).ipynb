{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorgel/.virtualenvs/dl4cv/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(width, height, depth, classes):\n",
    "\t# initialize the model along with the input shape to be\n",
    "\t# \"channels last\" and the channels dimension itself\n",
    "\tmodel = Sequential()\n",
    "\tinputShape = (height, width, depth)\n",
    "\tchanDim = -1\n",
    " \n",
    "\t# if we are using \"channels first\", update the input shape\n",
    "\t# and channels dimension\n",
    "\tif K.image_data_format() == \"channels_first\":\n",
    "\t\tinputShape = (depth, height, width)\n",
    "\t\tchanDim = 1\n",
    "\t# CONV => RELU => POOL\n",
    "\tmodel.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "\t\tinput_shape=inputShape))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\t# (CONV => RELU) * 2 => POOL\n",
    "\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\t# (CONV => RELU) * 2 => POOL\n",
    "\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.25))\n",
    "\t# first (and only) set of FC => RELU layers\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(1024))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(BatchNormalization())\n",
    "\tmodel.add(Dropout(0.5))\n",
    " \n",
    "\t# softmax classifier\n",
    "\tmodel.add(Dense(classes))\n",
    "\tmodel.add(Activation(\"softmax\"))\n",
    " \n",
    "\t# return the constructed network architecture\n",
    "\treturn model        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import model_from_json\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# batch size, and image dimensions\n",
    "EPOCHS = 98\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "IMAGE_DIMS = (96, 96, 3)\n",
    " \n",
    "# initialize the data and labels\n",
    "data = []\n",
    "labels = []\n",
    " \n",
    "# grab the image paths and randomly shuffle them\n",
    "print(\"[INFO] loading images...\")\n",
    "path = '/home/jorgel/Documents/faceRec/dataset'\n",
    "imagePaths = sorted(list(paths.list_images(path)))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "\t# load the image, pre-process it, and store it in the data list\n",
    "\timage = cv2.imread(imagePath)\n",
    "\timage = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "\timage = img_to_array(image)\n",
    "\tdata.append(image)\n",
    " \n",
    "\t# extract the class label from the image path and update the\n",
    "\t# labels list\n",
    "\tlabel = imagePath.split(os.path.sep)[-2]\n",
    "\tlabels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data matrix: 347.76MB\n",
      "labels [[0 0 0 ... 0 1 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "print(\"[INFO] data matrix: {:.2f}MB\".format(\n",
    "\tdata.nbytes / (1024 * 1000.0)))\n",
    " \n",
    "# binarize the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "print(\"labels {}\".format(labels))\n",
    "# partition the data into training and testing splits using 80% of\n",
    "# the data for training and the remaining 20% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "\tlabels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size 1610\n",
      "(1610, 7)\n",
      "(1288, 96, 96, 3) (322, 96, 96, 3)\n",
      "(322, 96, 96, 3) (322, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size {}\".format(len(labels)))\n",
    "print(labels.shape)\n",
    "print(trainX.shape, testX.shape)\n",
    "print(testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/98\n",
      "40/40 [==============================] - 63s 2s/step - loss: 3.0986 - acc: 0.1571 - val_loss: 3.4136 - val_acc: 0.1273\n",
      "Epoch 2/98\n",
      "40/40 [==============================] - 65s 2s/step - loss: 2.7163 - acc: 0.1451 - val_loss: 3.0755 - val_acc: 0.1304\n",
      "Epoch 3/98\n",
      "40/40 [==============================] - 61s 2s/step - loss: 2.5536 - acc: 0.1493 - val_loss: 2.7377 - val_acc: 0.1118\n",
      "Epoch 4/98\n",
      "40/40 [==============================] - 60s 2s/step - loss: 2.5409 - acc: 0.1484 - val_loss: 4.0391 - val_acc: 0.1118\n",
      "Epoch 5/98\n",
      "40/40 [==============================] - 64s 2s/step - loss: 2.5303 - acc: 0.1602 - val_loss: 3.8807 - val_acc: 0.1460\n",
      "Epoch 6/98\n",
      "40/40 [==============================] - 64s 2s/step - loss: 2.4540 - acc: 0.1554 - val_loss: 2.2615 - val_acc: 0.1460\n",
      "Epoch 7/98\n",
      "40/40 [==============================] - 64s 2s/step - loss: 2.4150 - acc: 0.1703 - val_loss: 2.1994 - val_acc: 0.1429\n",
      "Epoch 8/98\n",
      "40/40 [==============================] - 66s 2s/step - loss: 2.3261 - acc: 0.1914 - val_loss: 2.2558 - val_acc: 0.1491\n",
      "Epoch 9/98\n",
      "40/40 [==============================] - 61s 2s/step - loss: 2.2917 - acc: 0.1758 - val_loss: 2.0367 - val_acc: 0.1553\n",
      "Epoch 10/98\n",
      "40/40 [==============================] - 62s 2s/step - loss: 2.2553 - acc: 0.1696 - val_loss: 2.0546 - val_acc: 0.1522\n",
      "Epoch 11/98\n",
      "40/40 [==============================] - 65s 2s/step - loss: 2.1599 - acc: 0.2063 - val_loss: 2.0154 - val_acc: 0.1988\n",
      "Epoch 12/98\n",
      "40/40 [==============================] - 63s 2s/step - loss: 2.1053 - acc: 0.2453 - val_loss: 2.2485 - val_acc: 0.2019\n",
      "Epoch 13/98\n",
      "40/40 [==============================] - 63s 2s/step - loss: 2.0116 - acc: 0.2650 - val_loss: 2.2963 - val_acc: 0.2298\n",
      "Epoch 14/98\n",
      "40/40 [==============================] - 63s 2s/step - loss: 1.9804 - acc: 0.2695 - val_loss: 2.6579 - val_acc: 0.3106\n",
      "Epoch 15/98\n",
      "40/40 [==============================] - 60s 2s/step - loss: 1.8325 - acc: 0.3132 - val_loss: 10.0224 - val_acc: 0.1491\n",
      "Epoch 16/98\n",
      "40/40 [==============================] - 61s 2s/step - loss: 1.7814 - acc: 0.3281 - val_loss: 2.8908 - val_acc: 0.2453\n",
      "Epoch 17/98\n",
      "40/40 [==============================] - 64s 2s/step - loss: 1.6917 - acc: 0.3562 - val_loss: 2.3831 - val_acc: 0.2050\n",
      "Epoch 18/98\n",
      "40/40 [==============================] - 62s 2s/step - loss: 1.7502 - acc: 0.3164 - val_loss: 2.2342 - val_acc: 0.2298\n",
      "Epoch 19/98\n",
      "40/40 [==============================] - 61s 2s/step - loss: 1.6823 - acc: 0.3750 - val_loss: 1.5523 - val_acc: 0.4348\n",
      "Epoch 20/98\n",
      "40/40 [==============================] - 61s 2s/step - loss: 1.5809 - acc: 0.3883 - val_loss: 2.4857 - val_acc: 0.2702\n",
      "Epoch 21/98\n",
      "40/40 [==============================] - 62s 2s/step - loss: 1.4709 - acc: 0.4398 - val_loss: 1.5609 - val_acc: 0.4317\n",
      "Epoch 22/98\n",
      "40/40 [==============================] - 59s 1s/step - loss: 1.4535 - acc: 0.4515 - val_loss: 2.1859 - val_acc: 0.3075\n",
      "Epoch 23/98\n",
      "40/40 [==============================] - 60s 2s/step - loss: 1.4317 - acc: 0.4555 - val_loss: 1.9841 - val_acc: 0.3261\n",
      "Epoch 24/98\n",
      "40/40 [==============================] - 61s 2s/step - loss: 1.3043 - acc: 0.4719 - val_loss: 1.5730 - val_acc: 0.4006\n",
      "Epoch 25/98\n",
      "40/40 [==============================] - 63s 2s/step - loss: 1.2224 - acc: 0.5210 - val_loss: 1.2334 - val_acc: 0.5186\n",
      "Epoch 26/98\n",
      "40/40 [==============================] - 63s 2s/step - loss: 1.2406 - acc: 0.5203 - val_loss: 1.4217 - val_acc: 0.4627\n",
      "Epoch 27/98\n",
      "40/40 [==============================] - 62s 2s/step - loss: 1.2658 - acc: 0.5273 - val_loss: 3.3455 - val_acc: 0.2422\n",
      "Epoch 28/98\n",
      "40/40 [==============================] - 62s 2s/step - loss: 1.2036 - acc: 0.5437 - val_loss: 1.5084 - val_acc: 0.4503\n",
      "Epoch 29/98\n",
      "40/40 [==============================] - 61s 2s/step - loss: 1.3183 - acc: 0.4790 - val_loss: 4.1310 - val_acc: 0.2547\n",
      "Epoch 30/98\n",
      "40/40 [==============================] - 64s 2s/step - loss: 1.2299 - acc: 0.4907 - val_loss: 4.8490 - val_acc: 0.2019\n",
      "Epoch 31/98\n",
      "40/40 [==============================] - 64s 2s/step - loss: 1.1499 - acc: 0.5359 - val_loss: 1.2607 - val_acc: 0.5839\n",
      "Epoch 32/98\n",
      "40/40 [==============================] - 64s 2s/step - loss: 1.0908 - acc: 0.5734 - val_loss: 1.5066 - val_acc: 0.4627\n",
      "Epoch 33/98\n",
      "40/40 [==============================] - 65s 2s/step - loss: 1.0212 - acc: 0.5835 - val_loss: 0.9569 - val_acc: 0.6304\n",
      "Epoch 34/98\n",
      "40/40 [==============================] - 65s 2s/step - loss: 1.0306 - acc: 0.5586 - val_loss: 0.9847 - val_acc: 0.6118\n",
      "Epoch 35/98\n",
      "40/40 [==============================] - 66s 2s/step - loss: 0.9995 - acc: 0.5985 - val_loss: 1.1328 - val_acc: 0.5435\n",
      "Epoch 36/98\n",
      "40/40 [==============================] - 66s 2s/step - loss: 0.9517 - acc: 0.6148 - val_loss: 3.5322 - val_acc: 0.3634\n",
      "Epoch 37/98\n",
      "40/40 [==============================] - 61s 2s/step - loss: 0.9743 - acc: 0.6181 - val_loss: 1.3006 - val_acc: 0.5590\n",
      "Epoch 38/98\n",
      "40/40 [==============================] - 61s 2s/step - loss: 0.9887 - acc: 0.6086 - val_loss: 2.1047 - val_acc: 0.3820\n",
      "Epoch 39/98\n",
      "40/40 [==============================] - 65s 2s/step - loss: 0.9415 - acc: 0.6329 - val_loss: 1.3765 - val_acc: 0.5714\n",
      "Epoch 40/98\n",
      "40/40 [==============================] - 63s 2s/step - loss: 0.8859 - acc: 0.6438 - val_loss: 1.7009 - val_acc: 0.4472\n",
      "Epoch 41/98\n",
      "40/40 [==============================] - 63s 2s/step - loss: 0.9080 - acc: 0.6454 - val_loss: 0.9874 - val_acc: 0.6708\n",
      "Epoch 42/98\n",
      "40/40 [==============================] - 60s 1s/step - loss: 0.8851 - acc: 0.6406 - val_loss: 2.7165 - val_acc: 0.3509\n",
      "Epoch 43/98\n",
      "40/40 [==============================] - 60s 2s/step - loss: 0.8615 - acc: 0.6625 - val_loss: 1.6690 - val_acc: 0.5683\n",
      "Epoch 44/98\n",
      "40/40 [==============================] - 61s 2s/step - loss: 0.8668 - acc: 0.6703 - val_loss: 1.0102 - val_acc: 0.6211\n",
      "Epoch 45/98\n",
      "40/40 [==============================] - 59s 1s/step - loss: 0.8544 - acc: 0.6624 - val_loss: 0.7300 - val_acc: 0.7422\n",
      "Epoch 46/98\n",
      "40/40 [==============================] - 62s 2s/step - loss: 0.8019 - acc: 0.6789 - val_loss: 0.9080 - val_acc: 0.6553\n",
      "Epoch 47/98\n",
      "40/40 [==============================] - 66s 2s/step - loss: 0.8346 - acc: 0.6548 - val_loss: 1.1173 - val_acc: 0.6491\n",
      "Epoch 48/98\n",
      "40/40 [==============================] - 70s 2s/step - loss: 0.7438 - acc: 0.7055 - val_loss: 1.0921 - val_acc: 0.6584\n",
      "Epoch 49/98\n",
      "40/40 [==============================] - 58s 1s/step - loss: 0.7936 - acc: 0.7025 - val_loss: 1.9344 - val_acc: 0.4814\n",
      "Epoch 50/98\n",
      "40/40 [==============================] - 59s 1s/step - loss: 0.7824 - acc: 0.6905 - val_loss: 1.8420 - val_acc: 0.5186\n",
      "Epoch 51/98\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "print(\"[INFO] compiling model...\")\n",
    "model = build(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],\n",
    "\tdepth=IMAGE_DIMS[2], classes=len(lb.classes_))\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    " \n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator(\n",
    "\taug.flow(trainX, trainY, batch_size=BS),\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tsteps_per_epoch=len(trainX) // BS,\n",
    "\tepochs=EPOCHS, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig(\"EmoTrain_1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(trainX, trainY, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"EmoClassModel.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"EmoClassWeights.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('EmoClassModel.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"EmoClassWeights.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "print('Model Summary:')\n",
    "print(loaded_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(testX, testY, verbose=1)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
